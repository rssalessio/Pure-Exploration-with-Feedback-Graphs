{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from environment import run_experiment, RunParameters, RunStatistics\n",
    "from baifg.model.feedback_graph import FeedbackGraph\n",
    "from baifg.model.reward_model import GaussianRewardModel, RewardType\n",
    "from baifg.algorithms.eps_greedy import EpsilonGreedy, EpsilonGreedyParameters\n",
    "from baifg.algorithms.ucb import UCB\n",
    "from baifg.algorithms.exp3g import Exp3G, Exp3GParameters\n",
    "from baifg.algorithms.tas_fg import TaSFG, TaSFGParameters\n",
    "from baifg.algorithms.base.graph_estimator import GraphEstimator\n",
    "from baifg.algorithms.base.base_algorithm import BaseAlg\n",
    "from baifg.utils.graphs import make_loopless_clique\n",
    "from baifg.utils.utils import approximate_solution#, approximate_solution_new\n",
    "from baifg.utils.characteristic_time import compute_characteristic_time, evaluate_characteristic_time\n",
    "from itertools import product\n",
    "from typing import List, NamedTuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_model(algo_name: BaseAlg, algo_params: NamedTuple, K: int, fg: FeedbackGraph, delta: float, informed: bool) -> BaseAlg:\n",
    "    if algo_name == EpsilonGreedy:\n",
    "        return EpsilonGreedy(\n",
    "            GraphEstimator.optimistic_graph(K, informed=informed, known=False),\n",
    "            fg.reward_model.reward_type,\n",
    "            delta=delta,\n",
    "            parameters=algo_params)\n",
    "    elif algo_name == UCB:\n",
    "        return UCB(\n",
    "            GraphEstimator.optimistic_graph(K, informed=informed, known=False),\n",
    "            reward_type=fg.reward_model.reward_type,\n",
    "            delta=delta)\n",
    "    elif algo_name == Exp3G:\n",
    "        return Exp3G(\n",
    "            GraphEstimator.optimistic_graph(K, informed=informed, known=False),\n",
    "            reward_type=fg.reward_model.reward_type,\n",
    "            delta=delta,\n",
    "            parameters=algo_params\n",
    "        )\n",
    "    elif algo_name == TaSFG:\n",
    "        return TaSFG(\n",
    "            GraphEstimator.optimistic_graph(K, informed=informed, known=False),\n",
    "            reward_type=fg.reward_model.reward_type,\n",
    "            delta=delta, parameters=TaSFGParameters(update_frequency=2 * K)\n",
    "        )\n",
    "    raise Exception('Algorithm not found')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281.74663856812384\n",
      "[9.84336949e-01 1.56629977e-02 9.19456306e-08 0.00000000e+00\n",
      " 0.00000000e+00]\n",
      "[0.2358123  0.24699305 0.20830086 0.23855667 0.07033712]\n",
      "------\n",
      "[0.0133136  0.29530109 0.70234938 0.29765054 0.70234948]\n",
      "[0.68419668 0.11368575 0.66179451 0.13284296 0.7831484 ]\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.  , 0.75, 0.5 , 0.25, 0.25])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=5\n",
    "fg=make_loopless_clique(p=0.3, mu=np.linspace(0, 1, K))\n",
    "\n",
    "sol = compute_characteristic_time(fg)\n",
    "approx = approximate_solution(fg, normalize=True)\n",
    "# approx_new = approximate_solution_new(fg.reward_model, fg.graph, normalize=True)\n",
    "\n",
    "print(evaluate_characteristic_time(approx, fg))\n",
    "# print(evaluate_characteristic_time(approx_new, fg))\n",
    "print(sol.wstar)\n",
    "print(approx)\n",
    "# print(approx_new)\n",
    "\n",
    "print('------')\n",
    "print(sol.mstar)\n",
    "print(fg.graph.G.T @ approx)\n",
    "# print(fg.graph.G.T @ approx_new)\n",
    "print('-----')\n",
    "GG = fg.graph.G @ fg.graph.G.T\n",
    "\n",
    "fg.reward_model.gaps\n",
    "#print(fg.reward_model.mu)\n",
    "# algo = make_model(algo_name=TaSFG, algo_params=TaSFGParameters(update_frequency=5, ),\n",
    "#                    K=fg.K, fg=fg, delta=1e-2, informed=False)\n",
    "# results = run_experiment(fg=fg, algo=algo, seed=0)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43malgo\u001b[49m\u001b[38;5;241m.\u001b[39mN)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(algo\u001b[38;5;241m.\u001b[39mreward\u001b[38;5;241m.\u001b[39mM)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(algo\u001b[38;5;241m.\u001b[39mreward\u001b[38;5;241m.\u001b[39mmu)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "print(algo.N)\n",
    "print(algo.reward.M)\n",
    "print(algo.reward.mu)\n",
    "print(algo.graph.G.round(2))\n",
    "print(fg.graph.G)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
